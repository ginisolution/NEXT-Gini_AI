import "server-only";
import { VertexAI, HarmBlockThreshold, HarmCategory } from "@google-cloud/vertexai";
import {
  getGoogleCredentials,
  getGoogleProjectId,
  getGoogleLocation,
} from "@/lib/google/credentials";

/**
 * Google Vertex AI ì„œë¹„ìŠ¤
 *
 * - Gemini 2.5 Pro: ëŒ€ë³¸ ìƒì„± + PDF ë¶„ì„
 * - Nano Banana: ì»¤ìŠ¤í…€ ì•„ë°”íƒ€ + ì”¬ ë°°ê²½ ì´ë¯¸ì§€
 * - Veo 3.1: ì”¬ ë°°ê²½ ì˜ìƒ (image-to-video)
 */

const PROJECT_ID = getGoogleProjectId();
const LOCATION = getGoogleLocation();
const credentials = getGoogleCredentials();

const vertexAI = new VertexAI({
  project: PROJECT_ID,
  location: LOCATION,
  ...(credentials && {
    googleAuthOptions: {
      credentials,
    },
  }),
});

/**
 * Gemini 2.5 Pro - ëŒ€ë³¸ ìƒì„±
 *
 * @param pdfBase64 - PDF íŒŒì¼ Base64 ì¸ì½”ë”©
 * @param duration - ì˜ìƒ ê¸¸ì´ (30/60/180ì´ˆ)
 * @returns ìƒì„±ëœ ëŒ€ë³¸ (ì”¬ ë°°ì—´)
 */
export async function generateScript(
  pdfBase64: string,
  duration: 30 | 60 | 180
) {
  const model = vertexAI.getGenerativeModel({
    model: "gemini-2.0-flash-exp",
    generationConfig: {
      temperature: 0.7,
      maxOutputTokens: 8192,
    },
    safetySettings: [
      {
        category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
        threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
      },
    ],
  });

  const prompt = `
ë‹¹ì‹ ì€ ë°œí‘œ ìë£Œë¥¼ ë¶„ì„í•˜ì—¬ ì•„ë°”íƒ€ê°€ ë°œí‘œí•  ëŒ€ë³¸ì„ ìƒì„±í•˜ëŠ” AIì…ë‹ˆë‹¤.

ì²¨ë¶€ëœ PDF ë°œí‘œ ìë£Œë¥¼ ë¶„ì„í•˜ì—¬ ${duration}ì´ˆ ê¸¸ì´ì˜ ì˜ìƒ ëŒ€ë³¸ì„ ìƒì„±í•˜ì„¸ìš”.

ìš”êµ¬ì‚¬í•­:
1. ì „ì²´ ì˜ìƒ ê¸¸ì´: ì •í™•íˆ ${duration}ì´ˆ
2. ì”¬ êµ¬ì„±: 8ì´ˆì”© ë‚˜ëˆ ì„œ ì´ ${duration / 8}ê°œ ì”¬ (Veo 3.1 ì˜ìƒ ê¸¸ì´ì— ë§ì¶¤)
3. ê° ì”¬ë§ˆë‹¤ ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨:
   - ëŒ€ë³¸ (script): ì•„ë°”íƒ€ê°€ ë§í•  ë‚´ìš© (ì •í™•íˆ 8ì´ˆ ë¶„ëŸ‰)
   - ì‹œê°ì  ì„¤ëª… (visualDescription): ë°°ê²½ì— í‘œì‹œí•  ë‚´ìš© ì„¤ëª… (í•˜ìœ„ í˜¸í™˜ì„±ìš©)
   - ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ (imagePrompt): Nano Banana ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ìš© í”„ë¡¬í”„íŠ¸
     * 16:9 ë¹„ìœ¨, í¬í† ë¦¬ì–¼ë¦¬ìŠ¤í‹± ìŠ¤íƒ€ì¼
     * êµ¬ì²´ì ì¸ ì¡°ëª…, ìƒ‰ìƒ, êµ¬ë„, ì§ˆê° í¬í•¨
     * ì˜ˆ: "Modern office interior with large windows, soft natural daylight, minimalist wooden desk, potted plants, 16:9 composition, photorealistic, 8k quality, cinematic lighting, professional photography"
   - ì˜ìƒ í”„ë¡¬í”„íŠ¸ (videoPrompt): Veo 3.1 ì˜ìƒ ìƒì„± ëª¨ë¸ìš© í”„ë¡¬í”„íŠ¸
     * ì¹´ë©”ë¼ ì›€ì§ì„ (slow pan, gentle zoom, static shot)
     * ë™ì  ìš”ì†Œ (subtle movement, light changes)
     * 8ì´ˆ ê¸¸ì´ì— ì í•©í•œ ë³€í™”
     * ì˜ˆ: "Slow camera pan from left to right across the office space, subtle light movement through windows, smooth transition, 8 seconds duration, cinematic motion"
   - ìš°ì„ ìˆœìœ„ (priority): "high" (ì¤‘ìš”), "medium" (ë³´í†µ), "low" (ëœ ì¤‘ìš”)

ì‘ë‹µ í˜•ì‹ (JSON):
{
  "scenes": [
    {
      "sceneNumber": 1,
      "script": "ì•ˆë…•í•˜ì„¸ìš”...",
      "visualDescription": "í˜„ëŒ€ì ì¸ ì‚¬ë¬´ì‹¤ ë°°ê²½",
      "imagePrompt": "Modern office interior with large windows, soft natural daylight, minimalist wooden desk, potted plants, 16:9 composition, photorealistic, 8k quality, cinematic lighting",
      "videoPrompt": "Slow camera pan across the office space, subtle light movement through windows, smooth transition, 8 seconds duration",
      "priority": "high"
    }
  ]
}
`;

  const result = await model.generateContent({
    contents: [
      {
        role: "user",
        parts: [
          { text: prompt },
          {
            inlineData: {
              mimeType: "application/pdf",
              data: pdfBase64,
            },
          },
        ],
      },
    ],
  });

  const response = result.response;
  const text = response.candidates?.[0].content.parts[0].text || "";

  // ë””ë²„ê¹…: Gemini ì›ì‹œ ì‘ë‹µ í™•ì¸
  console.log("ğŸ¤– Gemini Raw Response:");
  console.log("=".repeat(80));
  console.log(text);
  console.log("=".repeat(80));

  // JSON íŒŒì‹±
  const jsonMatch = text.match(/\{[\s\S]*\}/);
  if (!jsonMatch) {
    console.error("âŒ Failed to find JSON in Gemini response");
    throw new Error("Failed to parse Gemini response");
  }

  const parsedJson = JSON.parse(jsonMatch[0]);

  // ë””ë²„ê¹…: íŒŒì‹±ëœ JSON í™•ì¸
  console.log("ğŸ“¦ Parsed JSON:");
  console.log(JSON.stringify(parsedJson, null, 2));

  return parsedJson;
}

/**
 * Nano Banana - ì»¤ìŠ¤í…€ ì•„ë°”íƒ€ ì´ë¯¸ì§€ ìƒì„±
 *
 * @param settings - ì•„ë°”íƒ€ ë””ìì¸ ì„¤ì •
 * @returns ìƒì„±ëœ ì´ë¯¸ì§€ Buffer
 */
export async function generateAvatarDesign(settings: {
  gender: string;
  ageRange: string;
  style: string;
  expression: string;
  background: string;
  nationality?: string;
}): Promise<Buffer> {
  // í”„ë¡¬í”„íŠ¸ ìƒì„±
  const prompt = buildAvatarPrompt(settings);

  // Gemini 2.5 Flash Image ëª¨ë¸ ì‚¬ìš© (ì»¤ìŠ¤í…€ ì•„ë°”íƒ€ ì´ë¯¸ì§€ ìƒì„±)
  // ì°¸ê³ : https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash-image
  const model = vertexAI.getGenerativeModel({
    model: "gemini-2.5-flash-image", // Gemini 2.5 Flash Image ëª¨ë¸
  });

  const result = await model.generateContent({
    contents: [
      {
        role: "user",
        parts: [{ text: prompt }],
      },
    ],
    generationConfig: {
      temperature: 0.4,
      candidateCount: 1,
    },
  });

  // ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ
  const imageData = result.response.candidates?.[0]?.content?.parts?.[0];
  if (!imageData || !("inlineData" in imageData)) {
    throw new Error("No image data in Nano Banana response");
  }

  // Base64 ë””ì½”ë”©í•˜ì—¬ Buffer ë°˜í™˜
  const base64Data = imageData.inlineData?.data || "";
  return Buffer.from(base64Data, "base64");
}

/**
 * ì•„ë°”íƒ€ í”„ë¡¬í”„íŠ¸ ìƒì„±
 */
function buildAvatarPrompt(settings: {
  gender: string;
  ageRange: string;
  style: string;
  expression: string;
  background: string;
  nationality?: string;
}): string {
  const { gender, ageRange, style, expression, background, nationality } = settings;

  // êµ­ì ì— ë”°ë¥¸ ethnicity ì„¤ëª… ì¶”ê°€
  const ethnicityMap: Record<string, string> = {
    korean: "East Asian, Korean ethnicity",
    japanese: "East Asian, Japanese ethnicity",
    american: "Caucasian, American ethnicity",
  };

  const ethnicityDescription = nationality
    ? ethnicityMap[nationality.toLowerCase()] || "diverse ethnicity"
    : "diverse ethnicity";

  return `
A photorealistic portrait of a ${gender} person in their ${ageRange},
${ethnicityDescription}, ${style} style, with a ${expression} expression.
Background: ${background}.
Professional headshot, centered composition, 1:1 aspect ratio,
8k resolution, raw photo, hyper-realistic, detailed skin texture, cinematic lighting, depth of field,
high quality, studio lighting, sharp focus.
Front-facing view, suitable for video avatar animation.
`.trim();
}

/**
 * Nano Banana - ì”¬ ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±
 *
 * @param visualDescription - ì‹œê°ì  ì„¤ëª…
 * @returns ìƒì„±ëœ ì´ë¯¸ì§€ Buffer
 */
export async function generateBackgroundImage(
  visualDescription: string
): Promise<Buffer> {
  // TODO: Vertex AI Imagen API êµ¬í˜„
  // í˜„ì¬ëŠ” placeholder - 1x1 íˆ¬ëª… PNG ë°˜í™˜

  // 1x1 íˆ¬ëª… PNG (89 bytes)
  const pngData = Buffer.from([
    0x89, 0x50, 0x4e, 0x47, 0x0d, 0x0a, 0x1a, 0x0a,
    0x00, 0x00, 0x00, 0x0d, 0x49, 0x48, 0x44, 0x52,
    0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x01,
    0x08, 0x06, 0x00, 0x00, 0x00, 0x1f, 0x15, 0xc4,
    0x89, 0x00, 0x00, 0x00, 0x0a, 0x49, 0x44, 0x41,
    0x54, 0x78, 0x9c, 0x63, 0x00, 0x01, 0x00, 0x00,
    0x05, 0x00, 0x01, 0x0d, 0x0a, 0x2d, 0xb4, 0x00,
    0x00, 0x00, 0x00, 0x49, 0x45, 0x4e, 0x44, 0xae,
    0x42, 0x60, 0x82
  ]);

  console.warn(`Using placeholder image for: ${visualDescription}`);
  return pngData;
}

/**
 * Veo 3.1 - ë°°ê²½ ì˜ìƒ ìƒì„± (image-to-video)
 *
 * @param imageUrl - ê¸°ì¤€ ì´ë¯¸ì§€ URL
 * @param prompt - ì˜ìƒ ì„¤ëª…
 * @returns Operation ì •ë³´
 */
export async function generateVeoVideo(
  imageUrl: string,
  prompt: string
): Promise<{ name: string }> {
  const { GoogleAuth } = await import("google-auth-library");

  // Google Auth í´ë¼ì´ì–¸íŠ¸ ìƒì„±
  const auth = new GoogleAuth({
    scopes: ["https://www.googleapis.com/auth/cloud-platform"],
    ...(credentials && { credentials }),
  });

  const client = await auth.getClient();
  const accessTokenResponse = await client.getAccessToken();

  if (!accessTokenResponse.token) {
    throw new Error("Failed to obtain access token");
  }

  console.log(`ğŸ“¸ Downloading image from: ${imageUrl}`);

  // ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° Base64 ì¸ì½”ë”©
  const imageResponse = await fetch(imageUrl);
  if (!imageResponse.ok) {
    console.error(`âŒ Failed to fetch image: ${imageResponse.status} ${imageResponse.statusText}`);
    console.error(`   Image URL: ${imageUrl}`);
    throw new Error(`Failed to fetch image: ${imageResponse.statusText}`);
  }

  const imageBuffer = await imageResponse.arrayBuffer();
  const imageBase64 = Buffer.from(imageBuffer).toString("base64");
  console.log(`âœ… Image downloaded: ${imageBuffer.byteLength} bytes â†’ ${imageBase64.length} base64 chars`);

  // Veo 3.0 Fast API ì—”ë“œí¬ì¸íŠ¸ (predictLongRunning ì‚¬ìš©)
  const endpoint = `https://${LOCATION}-aiplatform.googleapis.com/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/veo-3.0-fast-generate-001:predictLongRunning`;

  // ì˜í™” í’ˆì§ˆ í”„ë¡¬í”„íŠ¸ ê°•í™”
  const cinematicPrompt = enhanceCinematicPrompt(prompt);

  console.log(`ğŸ¬ Calling Veo 3.1 API:`);
  console.log(`   Endpoint: ${endpoint}`);
  console.log(`   Prompt: ${cinematicPrompt.substring(0, 200)}...`);

  // API ìš”ì²­ (Veo í˜•ì‹)
  const response = await fetch(endpoint, {
    method: "POST",
    headers: {
      Authorization: `Bearer ${accessTokenResponse.token}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      instances: [
        {
          prompt: cinematicPrompt,
          image: {
            bytesBase64Encoded: imageBase64,
            mimeType: "image/png",
          },
        },
      ],
      parameters: {
        aspectRatio: "16:9",
        resolution: "720p",
        sampleCount: 1,
      },
    }),
  });

  if (!response.ok) {
    const errorText = await response.text();
    console.error("âŒ Veo API request failed:");
    console.error(`   Status: ${response.status} ${response.statusText}`);
    console.error(`   Endpoint: ${endpoint}`);
    console.error(`   Response:`, errorText.substring(0, 1000));
    throw new Error(`Veo API request failed: ${response.status} ${response.statusText}`);
  }

  const result = await response.json();

  // ë””ë²„ê¹…: Veo API ì „ì²´ ì‘ë‹µ í™•ì¸
  console.log(`âœ… Veo video generation API response:`);
  console.log(JSON.stringify(result, null, 2));

  // LRO operation name ì¶”ì¶œ
  const operationName = result.name;
  if (!operationName) {
    console.error("âŒ No operation name in Veo API response");
    console.error("   Full response:", JSON.stringify(result, null, 2));
    throw new Error("No operation name in Veo API response");
  }

  console.log(`âœ… Veo video generation started`);
  console.log(`   Operation name: ${operationName}`);
  console.log(`   Full response:`, JSON.stringify(result, null, 2).substring(0, 500));

  return { name: operationName };
}

/**
 * ì˜í™” í’ˆì§ˆ í”„ë¡¬í”„íŠ¸ ê°•í™”
 */
function enhanceCinematicPrompt(prompt: string): string {
  // ì´ë¯¸ cinematic í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
  if (prompt.toLowerCase().includes("cinematic")) {
    return prompt;
  }

  // ì˜í™” í’ˆì§ˆ í–¥ìƒ í‚¤ì›Œë“œ ì¶”ê°€
  const cinematicEnhancements = [
    "cinematic quality",
    "professional cinematography",
    "smooth camera movement",
    "dramatic lighting",
    "film-grade color grading",
    "8-second duration",
  ];

  return `${prompt}, ${cinematicEnhancements.join(", ")}`;
}

/**
 * Veo LRO (Long Running Operation) ìƒíƒœ í™•ì¸
 *
 * @param operationName - Operation name
 * @returns ìƒíƒœ ë° ê²°ê³¼
 */
export async function checkVeoOperation(operationName: string): Promise<{
  done: boolean;
  videoBuffer?: Buffer;
  error?: string;
}> {
  const { GoogleAuth } = await import("google-auth-library");
  const { Storage } = await import("@google-cloud/storage");

  // Google Auth í´ë¼ì´ì–¸íŠ¸ ìƒì„±
  const auth = new GoogleAuth({
    scopes: ["https://www.googleapis.com/auth/cloud-platform"],
    ...(credentials && { credentials }),
  });

  const client = await auth.getClient();
  const accessTokenResponse = await client.getAccessToken();

  if (!accessTokenResponse.token) {
    throw new Error("Failed to obtain access token");
  }

  // operationNameì—ì„œ location ë™ì  ì¶”ì¶œ
  // ì˜ˆ: "projects/.../locations/us-central1/..." â†’ "us-central1"
  const locationMatch = operationName.match(/\/locations\/([^\/]+)\//);
  const operationLocation = locationMatch ? locationMatch[1] : LOCATION;

  // LRO ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸ (ê³µì‹ ë¬¸ì„œ ì¤€ìˆ˜: fetchPredictOperation ì‚¬ìš©)
  // POST ë°©ì‹ìœ¼ë¡œ operationNameì„ bodyì— í¬í•¨í•˜ì—¬ ì „ì†¡
  const endpoint = `https://${operationLocation}-aiplatform.googleapis.com/v1/projects/${PROJECT_ID}/locations/${operationLocation}/publishers/google/models/veo-3.0-fast-generate-001:fetchPredictOperation`;

  console.log(`ğŸ” Veo LRO polling (fetchPredictOperation):`);
  console.log(`   Operation location: ${operationLocation}`);
  console.log(`   Operation name: ${operationName}`);
  console.log(`   Endpoint: ${endpoint}`);

  const response = await fetch(endpoint, {
    method: "POST",
    headers: {
      Authorization: `Bearer ${accessTokenResponse.token}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      operationName,
    }),
  });

  if (!response.ok) {
    const errorText = await response.text();
    console.error("âŒ Veo LRO polling failed:");
    console.error(`   Status: ${response.status} ${response.statusText}`);
    console.error(`   Operation: ${operationName}`);
    console.error(`   Extracted location: ${operationLocation}`);
    console.error(`   Default location (env): ${LOCATION}`);
    console.error(`   Endpoint: ${endpoint}`);
    console.error(`   Response:`, errorText.substring(0, 500));

    // 404 ì—ëŸ¬ëŠ” eventual consistency - ì¬ì‹œë„ ê³„ì†
    if (response.status === 404) {
      console.log("â³ 404 - Operation not yet available (eventual consistency)");
      console.log(`   Operation will be retried by polling function`);
      console.log(`   Location: ${operationLocation}`);
      return {
        done: false,  // â† FIXED: ì¬ì‹œë„ ê³„ì†
      };
    }

    // ë‹¤ë¥¸ HTTP ì—ëŸ¬ (ê¶Œí•œ, í• ë‹¹ëŸ‰ ë“±)ëŠ” ì‹¤íŒ¨ë¡œ ì²˜ë¦¬
    console.error("ğŸš¨ Non-404 error - marking as failed");
    return {
      done: true,
      error: `LRO polling failed: ${response.status} ${response.statusText}`,
    };
  }

  const operation = await response.json();

  // ì‘ì—…ì´ ì•„ì§ ì§„í–‰ ì¤‘ì¸ ê²½ìš°
  if (!operation.done) {
    console.log(`â³ Veo operation in progress: ${operationName}`);
    return {
      done: false,
    };
  }

  // ì—ëŸ¬ê°€ ë°œìƒí•œ ê²½ìš°
  if (operation.error) {
    console.error("Veo operation failed:", operation.error);
    return {
      done: true,
      error: operation.error.message || "Veo operation failed",
    };
  }

  // ì„±ê³µí•œ ê²½ìš° - ë¹„ë””ì˜¤ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
  try {
    // ğŸ” ì „ì²´ operation response ë¡œê¹… (ë””ë²„ê¹…ìš©)
    console.log(`ğŸ“‹ Full operation response:`, JSON.stringify(operation, null, 2));

    // Veo API ì‘ë‹µ í˜•ì‹: operation.response.videos[]
    const videos = operation.response?.videos;
    if (!videos || videos.length === 0) {
      console.error(`âŒ No videos in operation response!`);
      console.error(`   Operation name: ${operationName}`);
      console.error(`   Response structure:`, JSON.stringify(operation.response, null, 2));
      throw new Error("No generated videos in operation response");
    }

    const videoFile = videos[0];
    let videoBuffer: Buffer;

    // Case 1: GCS URIë¡œ ë°˜í™˜ëœ ê²½ìš° (outputGcsUri ì§€ì • ì‹œ)
    if (videoFile.gcsUri) {
      const gcsUri = videoFile.gcsUri;
      console.log(`ğŸ“¹ Downloading Veo video from GCS: ${gcsUri}`);

      // GCS URI íŒŒì‹±: gs://bucket-name/path/to/file.mp4
      const match = gcsUri.match(/^gs:\/\/([^\/]+)\/(.+)$/);
      if (!match) {
        console.error(`âŒ Invalid GCS URI format: ${gcsUri}`);
        throw new Error(`Invalid GCS URI format: ${gcsUri}`);
      }

      const [, bucketName, filePath] = match;

      console.log(`ğŸ“¦ GCS download details:`);
      console.log(`   Bucket: ${bucketName}`);
      console.log(`   File path: ${filePath}`);

      // Cloud Storage í´ë¼ì´ì–¸íŠ¸ë¡œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
      const storage = new Storage({
        ...(credentials && { credentials }),
      });

      const bucket = storage.bucket(bucketName);
      const file = bucket.file(filePath);

      const [downloadedBuffer] = await file.download();
      videoBuffer = downloadedBuffer;

      console.log(`âœ… Veo video downloaded from GCS: ${videoBuffer.length} bytes`);
    }
    // Case 2: Base64ë¡œ ë°˜í™˜ëœ ê²½ìš° (outputGcsUri ë¯¸ì§€ì • ì‹œ - ê¸°ë³¸ê°’)
    else if (videoFile.bytesBase64Encoded) {
      console.log(`ğŸ“¹ Veo video returned as Base64 (no GCS bucket specified)`);
      videoBuffer = Buffer.from(videoFile.bytesBase64Encoded, "base64");
      console.log(`âœ… Veo video decoded from Base64: ${videoBuffer.length} bytes`);
    }
    // Case 3: ë‘˜ ë‹¤ ì—†ëŠ” ê²½ìš° - ì—ëŸ¬
    else {
      console.error(`âŒ No video data in response!`);
      console.error(`   Video file structure:`, JSON.stringify(videoFile, null, 2));
      throw new Error("No gcsUri or bytesBase64Encoded in operation response");
    }

    return {
      done: true,
      videoBuffer,
    };
  } catch (error) {
    console.error("âŒ Failed to download Veo video:");
    console.error(`   Operation: ${operationName}`);
    console.error(`   Error type: ${error instanceof Error ? error.constructor.name : typeof error}`);
    console.error(`   Error message: ${error instanceof Error ? error.message : String(error)}`);

    if (error instanceof Error && error.stack) {
      console.error(`   Stack trace:`, error.stack);
    }

    return {
      done: true,
      error: error instanceof Error ? error.message : "Failed to download video",
    };
  }
}
