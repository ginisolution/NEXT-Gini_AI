import "server-only";
import { VertexAI, HarmBlockThreshold, HarmCategory, SchemaType } from "@google-cloud/vertexai";
import {
  getGoogleCredentials,
  getGoogleProjectId,
  getGoogleLocation,
} from "@/lib/google/credentials";

/**
 * Google Vertex AI ì„œë¹„ìŠ¤
 *
 * - Gemini 2.5 Pro: ëŒ€ë³¸ ìƒì„± + PDF ë¶„ì„
 * - Nano Banana: ì»¤ìŠ¤í…€ ì•„ë°”íƒ€ + ì”¬ ë°°ê²½ ì´ë¯¸ì§€
 * - Veo 3.1: ì”¬ ë°°ê²½ ì˜ìƒ (image-to-video)
 */

const PROJECT_ID = getGoogleProjectId();
const LOCATION = getGoogleLocation();
const credentials = getGoogleCredentials();

const vertexAI = new VertexAI({
  project: PROJECT_ID,
  location: LOCATION,
  ...(credentials && {
    googleAuthOptions: {
      credentials,
    },
  }),
});

/**
 * Gemini 2.5 Pro - ëŒ€ë³¸ ìƒì„±
 *
 * @param pdfBase64 - PDF íŒŒì¼ Base64 ì¸ì½”ë”©
 * @param duration - ì˜ìƒ ê¸¸ì´ (30/60/180ì´ˆ)
 * @returns ìƒì„±ëœ ëŒ€ë³¸ (ì”¬ ë°°ì—´)
 */
export async function generateScript(
  pdfBase64: string,
  duration: 30 | 60 | 180
) {
  const model = vertexAI.getGenerativeModel({
    model: "gemini-2.5-pro",
    generationConfig: {
      temperature: 0.7,
      maxOutputTokens: 16384, // ì¦ê°€: 8192 â†’ 16384 (180ì´ˆ 23ê°œ ì”¬ ìƒì„± ìœ„í•´)
      responseMimeType: "application/json", // JSON ì‘ë‹µ ê°•ì œ
      responseSchema: {
        type: SchemaType.OBJECT,
        properties: {
          scenes: {
            type: SchemaType.ARRAY,
            items: {
              type: SchemaType.OBJECT,
              properties: {
                sceneNumber: { type: SchemaType.INTEGER },
                script: { type: SchemaType.STRING },
                duration: { type: SchemaType.NUMBER },
                visualDescription: { type: SchemaType.STRING },
                imagePrompt: { type: SchemaType.STRING },
                videoPrompt: { type: SchemaType.STRING },
                emotion: { type: SchemaType.STRING }
              },
              required: ["sceneNumber", "script", "duration", "visualDescription"]
            }
          }
        },
        required: ["scenes"]
      }
    },
    safetySettings: [
      {
        category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
        threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
      },
    ],
  });

  const prompt = `
ë‹¹ì‹ ì€ ë°œí‘œ ìë£Œë¥¼ ë¶„ì„í•˜ì—¬ ì•„ë°”íƒ€ê°€ ë°œí‘œí•  ëŒ€ë³¸ì„ ìƒì„±í•˜ëŠ” AIì…ë‹ˆë‹¤.

ì²¨ë¶€ëœ PDF ë°œí‘œ ìë£Œë¥¼ ë¶„ì„í•˜ì—¬ ${duration}ì´ˆ ê¸¸ì´ì˜ ì˜ìƒ ëŒ€ë³¸ì„ ìƒì„±í•˜ì„¸ìš”.

ìš”êµ¬ì‚¬í•­:
1. ì „ì²´ ì˜ìƒ ê¸¸ì´: ì •í™•íˆ ${duration}ì´ˆ
2. ì”¬ êµ¬ì„±: 8ì´ˆì”© ë‚˜ëˆ ì„œ ì´ ${duration / 8}ê°œ ì”¬ (Veo 3.1 ì˜ìƒ ê¸¸ì´ì— ë§ì¶¤)
3. ê° ì”¬ë§ˆë‹¤ ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨:
   - ëŒ€ë³¸ (script): ì•„ë°”íƒ€ê°€ ë§í•  ë‚´ìš©
     * ğŸš¨ **ABSOLUTE LIMIT: ìµœëŒ€ 60ì (ê³µë°± ì œì™¸)**
     * ğŸš¨ **60ì ì´ˆê³¼ ì‹œ ì¦‰ì‹œ ê±°ë¶€ë©ë‹ˆë‹¤**
     * **ëª©í‘œ ì‹œê°„: ì •í™•íˆ 6-7ì´ˆ ë¶„ëŸ‰**
     * **ë¬¸ì¥ ìŠ¤íƒ€ì¼: ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ í†¤ (ë”±ë”±í•œ ì„¤ëª…ì²´ ê¸ˆì§€)**
     * **í•„ìˆ˜ ì›ì¹™**:
       - ì¸ì‚¬ë§/ìê¸°ì†Œê°œ ì ˆëŒ€ ê¸ˆì§€ ("ì•ˆë…•í•˜ì„¸ìš”", "ì—¬ëŸ¬ë¶„" ë“±)
       - ê´„í˜¸ í‘œí˜„ ì ˆëŒ€ ê¸ˆì§€ ("(ì ì‹œ ëœ¸ë“¤ì„)", "(ì˜ˆì‹œ)" ë“±)
       - ì„¤ëª…ë¬¸ ê¸ˆì§€ ("~ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ê² ìŠµë‹ˆë‹¤", "~ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤" ë“±)
       - í•µì‹¬ ë©”ì‹œì§€ë¥¼ ì¶©ë¶„íˆ ì„¤ëª…í•˜ë˜ ê°„ê²°í•˜ê²Œ (40~60ì ê¶Œì¥)
       - ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ì–´ì²´ ì‚¬ìš© (~ì£ , ~ë„¤ìš”, ~ê±°ë“ ìš”, ~ì–ì•„ìš”)
       - ì˜ì–´ëŠ” ê¼­ í•„ìš”í•  ë•Œë§Œ (í•œê¸€ë¡œ ëŒ€ì²´ ê°€ëŠ¥í•˜ë©´ ëŒ€ì²´)
       - êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ì˜ˆì‹œë¡œ ì„¤ë“ë ¥ ë†’ì´ê¸°
     * âœ… ì¢‹ì€ ì˜ˆì‹œë“¤ (ìì—°ìŠ¤ëŸ½ê³  ì ì ˆí•œ ê¸¸ì´):
       - "í´ë¡œë“œ ì½”ë“œëŠ” ì •ë§ ê°•ë ¥í•˜ì§€ë§Œ, ë¬´ì œí•œ ìš”ê¸ˆì œê°€ ì—†ì–´ì ¸ì„œ ë¹„ìš© ê´€ë¦¬ê°€ í•„ìˆ˜ê°€ ëì–´ìš”." (43ì) â† ì™„ë²½
       - "MCP ì„œë²„ë“¤ì„ ì „ë¶€ ì—°ê²°í•˜ë©´ ê¸°ëŠ¥ì€ ì¢‹ì§€ë§Œ, ì˜¤íˆë ¤ í† í° ë‚­ë¹„ê°€ ì‹¬í•´ì§ˆ ìˆ˜ ìˆê±°ë“ ìš”." (46ì) â† ì™„ë²½
       - "ì½”ë“œ ë¶„ì„ ì—ì´ì „íŠ¸ë¥¼ í™œìš©í•˜ë©´ í† í°ì„ 30%ë‚˜ ì ˆì•½í•˜ë©´ì„œë„ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•´ìš”." (49ì) â† ì™„ë²½
       - "ì»¨í…ìŠ¤íŠ¸ 7ì„ ì“°ë©´ AIê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ ìµœì‹  ê¸°ìˆ  ë¬¸ì„œë¥¼ ì½ê³  ì½”ë“œë¥¼ ì§œì¤˜ì„œ ê°œë°œì´ í›¨ì”¬ ë¹¨ë¼ì ¸ìš”." (52ì) â† ì™„ë²½
     * âŒ ë‚˜ìœ ì˜ˆì‹œë“¤ (ì ˆëŒ€ ê¸ˆì§€):
       - "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ì€ MCP ì„œë²„ í™œìš©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤." (ì¸ì‚¬ë§ + ì„¤ëª…ë¬¸)
       - "ì •ë§ ë†€ëì£ ? (ì ì‹œ ëœ¸ë“¤ì„) ì´ì œ ìì„¸íˆ ì•Œì•„ë³¼ê¹Œìš”?" (ê´„í˜¸ í‘œí˜„)
       - "í´ë¡œë“œ ì½”ë“œ ì§±" (ë„ˆë¬´ ì§§ìŒ, 20ì ë¯¸ë§Œ)
       - "ë³¸ ë°œí‘œì—ì„œëŠ” AI ì½”ë”© ë„êµ¬ì˜ íš¨ìœ¨ì  í™œìš© ë°©ì•ˆì— ëŒ€í•˜ì—¬ ìƒì„¸íˆ ì„¤ëª…ë“œë¦¬ê³ ì í•©ë‹ˆë‹¤." (ë”±ë”±í•œ ì„¤ëª…ì²´)
   - ì‹œê°ì  ì„¤ëª… (visualDescription): ë°°ê²½ì— í‘œì‹œí•  ë‚´ìš© ì„¤ëª… (í•˜ìœ„ í˜¸í™˜ì„±ìš©)
   - ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ (imagePrompt): Nano Banana ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ìš© í”„ë¡¬í”„íŠ¸
     * 16:9 ë¹„ìœ¨, í¬í† ë¦¬ì–¼ë¦¬ìŠ¤í‹± ìŠ¤íƒ€ì¼
     * êµ¬ì²´ì ì¸ ì¡°ëª…, ìƒ‰ìƒ, êµ¬ë„, ì§ˆê° í¬í•¨
     * ì˜ˆ: "Modern office interior with large windows, soft natural daylight, minimalist wooden desk, potted plants, 16:9 composition, photorealistic, 8k quality, cinematic lighting, professional photography"
   - ì˜ìƒ í”„ë¡¬í”„íŠ¸ (videoPrompt): Veo 3.1 ì˜ìƒ ìƒì„± ëª¨ë¸ìš© í”„ë¡¬í”„íŠ¸
     * ì¹´ë©”ë¼ ì›€ì§ì„ (slow pan, gentle zoom, static shot)
     * ë™ì  ìš”ì†Œ (subtle movement, light changes)
     * 8ì´ˆ ê¸¸ì´ì— ì í•©í•œ ë³€í™”
     * ì˜ˆ: "Slow camera pan from left to right across the office space, subtle light movement through windows, smooth transition, 8 seconds duration, cinematic motion"

ì‘ë‹µ í˜•ì‹ (JSON):
{
  "scenes": [
    {
      "sceneNumber": 1,
      "script": "v1.0ì€ ì½”ë“œ ì¤‘ì‹¬ í˜‘ì—… ì‹œëŒ€ë¥¼ ì—´ì—ˆìŠµë‹ˆë‹¤.",
      "visualDescription": "í˜„ëŒ€ì ì¸ ì‚¬ë¬´ì‹¤ ë°°ê²½",
      "imagePrompt": "Modern office interior with large windows, soft natural daylight, minimalist wooden desk, potted plants, 16:9 composition, photorealistic, 8k quality, cinematic lighting",
      "videoPrompt": "Slow camera pan across the office space, subtle light movement through windows, smooth transition, 8 seconds duration"
    }
  ]
}
`;

  const result = await model.generateContent({
    contents: [
      {
        role: "user",
        parts: [
          { text: prompt },
          {
            inlineData: {
              mimeType: "application/pdf",
              data: pdfBase64,
            },
          },
        ],
      },
    ],
  });

  const response = result.response;
  const text = response.candidates?.[0].content.parts[0].text || "";

  // ë””ë²„ê¹…: Gemini ì›ì‹œ ì‘ë‹µ í™•ì¸
  console.log("ğŸ¤– Gemini Raw Response (first 1000 chars):");
  console.log("=".repeat(80));
  console.log(text.substring(0, 1000));
  console.log("=".repeat(80));

  // JSON Schema ì ìš©ìœ¼ë¡œ ì‘ë‹µì´ í•­ìƒ ìœ íš¨í•œ JSONì´ë¯€ë¡œ ì§ì ‘ íŒŒì‹±
  let parsedJson;
  try {
    parsedJson = JSON.parse(text);
  } catch {
    // JSON Schemaê°€ ìˆì–´ë„ ë“œë¬¼ê²Œ ì‹¤íŒ¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ fallback
    console.warn("âš ï¸ Direct parse failed, trying regex extraction...");
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      console.error("âŒ Failed to find JSON in Gemini response");
      console.error("Response text:", text);
      throw new Error("Failed to parse Gemini response - no valid JSON found");
    }
    parsedJson = JSON.parse(jsonMatch[0]);
  }

  // ë””ë²„ê¹…: íŒŒì‹±ëœ JSON í™•ì¸
  console.log("ğŸ“¦ Parsed JSON - scenes count:", parsedJson.scenes?.length || 0);
  if (parsedJson.scenes && parsedJson.scenes.length > 0) {
    console.log("First scene:", JSON.stringify(parsedJson.scenes[0], null, 2));
    console.log("Last scene:", JSON.stringify(parsedJson.scenes[parsedJson.scenes.length - 1], null, 2));
  }

  // ğŸš¨ Gemini 2.5 Flashë¥¼ ì‚¬ìš©í•œ ìŠ¤í¬ë¦½íŠ¸ ê²€ì¦ ë° ìš”ì•½
  console.log("\nğŸ” ìŠ¤í¬ë¦½íŠ¸ ê²€ì¦ ë° ìš”ì•½ ì‹œì‘...");
  const invalidScenes: string[] = [];

  for (let i = 0; i < parsedJson.scenes.length; i++) {
    const scene = parsedJson.scenes[i];
    const sceneNum = i + 1;
    const originalScript = scene.script;

    console.log(`\nğŸ“ ì”¬ ${sceneNum} ì²˜ë¦¬ ì¤‘...`);
    console.log(`   ì›ë³¸: "${originalScript}" (${originalScript.replace(/\s/g, "").length}ì)`);

    // 1. ê´„í˜¸ ìë™ ì œê±° (TTSê°€ ê´„í˜¸ ì•ˆ ë‹¨ì–´ë¥¼ ì¤‘ë³µ ì½ëŠ” ë¬¸ì œ ë°©ì§€)
    let processedScript = originalScript;
    if (originalScript.includes("(") || originalScript.includes(")")) {
      console.warn(`   âš ï¸ ê´„í˜¸ ë°œê²¬ - ìë™ ì œê±° ì¤‘...`);
      // ê´„í˜¸ì™€ ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì œê±°: "ì»¤ì„œ(Cursor)" â†’ "ì»¤ì„œ"
      processedScript = originalScript.replace(/\([^)]*\)/g, '').trim();
      // ì—°ì† ê³µë°± ì •ë¦¬
      processedScript = processedScript.replace(/\s+/g, ' ');
      console.log(`   ğŸ”§ ê´„í˜¸ ì œê±° í›„: "${processedScript}" (${processedScript.replace(/\s/g, "").length}ì)`);
    }

    // 2. ì¸ì‚¬ë§ ê²€ì¦
    const greetings = ["ì•ˆë…•í•˜ì„¸ìš”", "ì•ˆë…•", "ì—¬ëŸ¬ë¶„", "ë°˜ê°‘ìŠµë‹ˆë‹¤"];
    if (greetings.some((greeting) => processedScript.includes(greeting))) {
      invalidScenes.push(`ì”¬ ${sceneNum}: ì¸ì‚¬ë§ í¬í•¨ ê¸ˆì§€ - "${processedScript}"`);
    }

    // 3. ì„¤ëª…ë¬¸ ê²€ì¦
    const explanations = [
      "ì´ì•¼ê¸°í•˜ê² ìŠµë‹ˆë‹¤",
      "ì†Œê°œí•©ë‹ˆë‹¤",
      "ì„¤ëª…í•˜ê² ìŠµë‹ˆë‹¤",
      "ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤",
      "ì— ëŒ€í•´",
    ];
    if (explanations.some((exp) => processedScript.includes(exp))) {
      invalidScenes.push(`ì”¬ ${sceneNum}: ì„¤ëª…ë¬¸ í¬í•¨ ê¸ˆì§€ - "${processedScript}"`);
    }

    // 4. ê¸¸ì´ ê²€ì¦ ë° AI ìš”ì•½
    try {
      const summarized = await validateAndSummarizeScript(processedScript);
      parsedJson.scenes[i].script = summarized;
      console.log(`   âœ… ìµœì¢…: "${summarized}" (${summarized.replace(/\s/g, "").length}ì)`);
    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      invalidScenes.push(`ì”¬ ${sceneNum}: ìš”ì•½ ì‹¤íŒ¨ - ${errorMsg}`);
      console.error(`   âŒ ìš”ì•½ ì‹¤íŒ¨: ${errorMsg}`);
    }
  }

  // ê²€ì¦ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë°œìƒ
  if (invalidScenes.length > 0) {
    console.error("\nâŒ ìŠ¤í¬ë¦½íŠ¸ ê²€ì¦ ì‹¤íŒ¨:");
    invalidScenes.forEach((error) => console.error(`   - ${error}`));
    throw new Error(
      `ìŠ¤í¬ë¦½íŠ¸ ê²€ì¦ ì‹¤íŒ¨ (${invalidScenes.length}ê°œ ì”¬):\n${invalidScenes.join("\n")}`
    );
  }

  console.log("\nâœ… ëª¨ë“  ì”¬ ìŠ¤í¬ë¦½íŠ¸ ê²€ì¦ ë° ìš”ì•½ ì™„ë£Œ");

  return parsedJson;
}

/**
 * Gemini 2.5 Flash - ìŠ¤í¬ë¦½íŠ¸ ê¸¸ì´ ê²€ì¦ ë° ìš”ì•½
 *
 * @param script - ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸
 * @returns 60ì ì´ë‚´ë¡œ ìš”ì•½ëœ ìŠ¤í¬ë¦½íŠ¸
 */
async function validateAndSummarizeScript(script: string): Promise<string> {
  const scriptLength = script.replace(/\s/g, "").length;

  // ì´ë¯¸ 60ì ì´ë‚´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
  if (scriptLength <= 60) {
    console.log(`âœ… ìŠ¤í¬ë¦½íŠ¸ ê¸¸ì´ OK: ${scriptLength}ì`);
    return script;
  }

  console.log(`âš ï¸ ìŠ¤í¬ë¦½íŠ¸ ê¸¸ì´ ì´ˆê³¼: ${scriptLength}ì â†’ ìš”ì•½ í•„ìš”`);

  // Gemini 2.5 Flash ëª¨ë¸ ì‚¬ìš© (ë¹ ë¥´ê³  ì €ë ´)
  const model = vertexAI.getGenerativeModel({
    model: "gemini-2.5-flash",
    generationConfig: {
      temperature: 0.3, // ì¼ê´€ì„± ìˆëŠ” ìš”ì•½
      maxOutputTokens: 100,
    },
  });

  const prompt = `
ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ë¥¼ **ì •í™•íˆ 60ì ì´ë‚´ (ê³µë°± ì œì™¸)**ë¡œ ìš”ì•½í•˜ì„¸ìš”.

ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸:
"${script}"

ìš”êµ¬ì‚¬í•­:
1. ğŸš¨ **ì ˆëŒ€ ì œí•œ: 60ì ì´ë‚´ (ê³µë°± ì œì™¸)**
2. í•µì‹¬ ë©”ì‹œì§€ë¥¼ ì¶©ë¶„íˆ ì„¤ëª…í•˜ë˜ ê°„ê²°í•˜ê²Œ (40~60ì ê¶Œì¥)
3. ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ì–´ì²´ (~ì£ , ~ë„¤ìš”, ~ê±°ë“ ìš”, ~ì–ì•„ìš”)
4. ì¸ì‚¬ë§/ì„¤ëª…ë¬¸ ì ˆëŒ€ ê¸ˆì§€
5. ê´„í˜¸ í‘œí˜„ ì ˆëŒ€ ê¸ˆì§€
6. ì˜ì–´ëŠ” ê¼­ í•„ìš”í•  ë•Œë§Œ
7. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ì˜ˆì‹œë¡œ ì„¤ë“ë ¥ ë†’ì´ê¸°

âœ… ì¢‹ì€ ì˜ˆì‹œ:
- "í´ë¡œë“œ ì½”ë“œëŠ” ì •ë§ ê°•ë ¥í•˜ì§€ë§Œ, ë¬´ì œí•œ ìš”ê¸ˆì œê°€ ì—†ì–´ì ¸ì„œ ë¹„ìš© ê´€ë¦¬ê°€ í•„ìˆ˜ê°€ ëì–´ìš”." (43ì)
- "MCP ì„œë²„ë“¤ì„ ì „ë¶€ ì—°ê²°í•˜ë©´ ê¸°ëŠ¥ì€ ì¢‹ì§€ë§Œ, ì˜¤íˆë ¤ í† í° ë‚­ë¹„ê°€ ì‹¬í•´ì§ˆ ìˆ˜ ìˆê±°ë“ ìš”." (46ì)

**ìš”ì•½ëœ ìŠ¤í¬ë¦½íŠ¸ë§Œ ì¶œë ¥í•˜ì„¸ìš” (ì„¤ëª… ì—†ì´):**
`.trim();

  const result = await model.generateContent(prompt);

  // ì•ˆì „í•œ ì‘ë‹µ ì¶”ì¶œ (optional chaining ì™„ì „ ì ìš©)
  const summarized = result.response.candidates?.[0]?.content?.parts?.[0]?.text?.trim();

  // Gemini ì‘ë‹µ ì‹¤íŒ¨ ì‹œ fallback: ê°•ì œ ìë¥´ê¸°
  if (!summarized) {
    console.warn(`âš ï¸ Gemini ìš”ì•½ ì‹¤íŒ¨ â†’ ê°•ì œ ìë¥´ê¸°`);
    console.warn(`   Response structure:`, JSON.stringify(result.response, null, 2).substring(0, 500));
    const trimmed = script.replace(/\s/g, "").slice(0, 60);
    console.warn(`   ê°•ì œ ì ˆë‹¨: "${trimmed}" (60ì)`);
    return trimmed;
  }

  const summarizedLength = summarized.replace(/\s/g, "").length;
  console.log(`âœ… ìš”ì•½ ì™„ë£Œ: ${scriptLength}ì â†’ ${summarizedLength}ì`);

  // ìš”ì•½ í›„ì—ë„ 60ì ì´ˆê³¼ ì‹œ ê°•ì œ ìë¥´ê¸°
  if (summarizedLength > 60) {
    const trimmed = summarized.replace(/\s/g, "").slice(0, 60);
    console.warn(`âš ï¸ ìš”ì•½ í›„ì—ë„ ì´ˆê³¼ â†’ ê°•ì œ ìë¥´ê¸°: ${trimmed}`);
    return trimmed;
  }

  return summarized;
}

/**
 * Nano Banana - ì»¤ìŠ¤í…€ ì•„ë°”íƒ€ ì´ë¯¸ì§€ ìƒì„±
 *
 * @param settings - ì•„ë°”íƒ€ ë””ìì¸ ì„¤ì •
 * @returns ìƒì„±ëœ ì´ë¯¸ì§€ Buffer
 */
export async function generateAvatarDesign(settings: {
  gender: string;
  ageRange: string;
  style: string;
  expression: string;
  background: string;
  nationality?: string;
}): Promise<Buffer> {
  // í”„ë¡¬í”„íŠ¸ ìƒì„±
  const prompt = buildAvatarPrompt(settings);

  // Gemini 2.5 Flash Image ëª¨ë¸ ì‚¬ìš© (ì»¤ìŠ¤í…€ ì•„ë°”íƒ€ ì´ë¯¸ì§€ ìƒì„±)
  // ì°¸ê³ : https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash-image
  const model = vertexAI.getGenerativeModel({
    model: "gemini-2.5-flash-image", // Gemini 2.5 Flash Image ëª¨ë¸
  });

  const result = await model.generateContent({
    contents: [
      {
        role: "user",
        parts: [{ text: prompt }],
      },
    ],
    generationConfig: {
      temperature: 0.4,
      candidateCount: 1,
    },
  });

  // ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ
  const imageData = result.response.candidates?.[0]?.content?.parts?.[0];
  if (!imageData || !("inlineData" in imageData)) {
    throw new Error("No image data in Nano Banana response");
  }

  // Base64 ë””ì½”ë”©í•˜ì—¬ Buffer ë°˜í™˜
  const base64Data = imageData.inlineData?.data || "";
  return Buffer.from(base64Data, "base64");
}

/**
 * ì•„ë°”íƒ€ í”„ë¡¬í”„íŠ¸ ìƒì„±
 */
function buildAvatarPrompt(settings: {
  gender: string;
  ageRange: string;
  style: string;
  expression: string;
  background: string;
  nationality?: string;
}): string {
  const { gender, ageRange, style, expression, background, nationality } = settings;

  // êµ­ì ì— ë”°ë¥¸ ethnicity ì„¤ëª… ì¶”ê°€
  const ethnicityMap: Record<string, string> = {
    korean: "East Asian, Korean ethnicity",
    japanese: "East Asian, Japanese ethnicity",
    american: "Caucasian, American ethnicity",
  };

  const ethnicityDescription = nationality
    ? ethnicityMap[nationality.toLowerCase()] || "diverse ethnicity"
    : "diverse ethnicity";

  return `
A photorealistic portrait of a ${gender} person in their ${ageRange},
${ethnicityDescription}, ${style} style, with a ${expression} expression.
Background: ${background}.
Professional headshot, centered composition, 1:1 aspect ratio,
8k resolution, raw photo, hyper-realistic, detailed skin texture, cinematic lighting, depth of field,
high quality, studio lighting, sharp focus.
Front-facing view, suitable for video avatar animation.
`.trim();
}

/**
 * ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ í–¥ìƒ
 *
 * Google ê³µì‹ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„¸í•œ ì„œìˆ í˜• ë¬¸ë‹¨ìœ¼ë¡œ í™•ì¥
 * https://ai.google.dev/gemini-api/docs/image-generation?hl=ko#image-generation-prompts
 *
 * @param rawPrompt - ì›ë³¸ í”„ë¡¬í”„íŠ¸
 * @param emotion - ê°ì •/ë¶„ìœ„ê¸° (ì¡°ëª…ê³¼ ìƒ‰ìƒ ê²°ì •)
 * @returns í–¥ìƒëœ í”„ë¡¬í”„íŠ¸
 */
function enhanceImagePrompt(
  rawPrompt: string,
  emotion: string = "professional"
): string {
  // ì´ë¯¸ ìƒì„¸í•œ í”„ë¡¬í”„íŠ¸ì¸ ê²½ìš° (100ì ì´ìƒ, ì¡°ëª…/ì¹´ë©”ë¼ ìš©ì–´ í¬í•¨)
  const hasLightingTerms = /light|lighting|illuminat|glow|shadow|bright/i.test(rawPrompt);
  const hasCameraTerms = /composition|angle|shot|focus|depth|lens|frame/i.test(rawPrompt);
  const hasQualityTerms = /8k|4k|photorealistic|cinematic|detailed|quality/i.test(rawPrompt);

  if (
    rawPrompt.length > 100 &&
    hasLightingTerms &&
    hasCameraTerms &&
    hasQualityTerms
  ) {
    console.log("   âœ“ Prompt already detailed, using as-is");
    return rawPrompt;
  }

  // ê°ì •ì— ë”°ë¥¸ ì¡°ëª… ë° ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ì„¤ì •
  const lightingAndColors = {
    professional: {
      lighting: "soft natural daylight streaming through large windows, balanced studio lighting with subtle shadows",
      colors: "cool neutral tones with hints of blue and gray, professional color grading",
      mood: "clean, focused, and sophisticated"
    },
    energetic: {
      lighting: "bright studio lighting with dynamic highlights, vibrant illumination creating energy",
      colors: "warm vibrant colors with pops of orange and yellow, saturated color palette",
      mood: "dynamic, engaging, and lively"
    },
    calm: {
      lighting: "gentle ambient light with soft diffusion, minimal shadows creating tranquility",
      colors: "cool blues and soft greens with pastel accents, serene color harmony",
      mood: "peaceful, relaxing, and contemplative"
    },
    innovative: {
      lighting: "modern LED accent lighting, sleek illumination with gradient effects",
      colors: "tech-inspired blues and purples, futuristic color scheme",
      mood: "cutting-edge, modern, and forward-thinking"
    },
    neutral: {
      lighting: "balanced natural and artificial lighting, even illumination across the scene",
      colors: "natural color palette with harmonious tones, realistic color reproduction",
      mood: "clear, straightforward, and authentic"
    }
  };

  const style = lightingAndColors[emotion.toLowerCase() as keyof typeof lightingAndColors]
    || lightingAndColors.neutral;

  // ê³µì‹ ê°€ì´ë“œë¼ì¸ì— ë”°ë¥¸ ì„œìˆ í˜• í”„ë¡¬í”„íŠ¸ êµ¬ì„±
  const enhancedPrompt = `
${rawPrompt.trim()}.
The scene is photographed with professional camera equipment, utilizing a wide-angle lens for comprehensive framing in 16:9 aspect ratio composition.
${style.lighting}, creating a ${style.mood} atmosphere throughout the environment.
The setting features ${style.colors}, with meticulous attention to material textures and surface qualities.
Rich environmental details include smooth polished surfaces, natural material textures, and carefully considered spatial depth.
The composition employs centered framing with strategic use of depth of field, ensuring sharp focus on key elements while maintaining contextual background clarity.
Rendered in 8k resolution with photorealistic quality, featuring cinematic color grading, high dynamic range, and professional post-processing for maximum visual impact and realism.
  `.trim();

  console.log(`   âœ“ Enhanced prompt from ${rawPrompt.length} to ${enhancedPrompt.length} characters`);
  return enhancedPrompt;
}

/**
 * Nano Banana - ì”¬ ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±
 *
 * @param imagePrompt - ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ (16:9, photorealistic)
 * @param emotion - ê°ì •/ë¶„ìœ„ê¸° (ì„ íƒì‚¬í•­, í”„ë¡¬í”„íŠ¸ í–¥ìƒì— ì‚¬ìš©)
 * @returns ìƒì„±ëœ ì´ë¯¸ì§€ Buffer
 */
export async function generateBackgroundImage(
  imagePrompt: string,
  emotion?: string
): Promise<Buffer> {
  console.log(`ğŸ¨ Generating background image with Gemini 2.5 Flash Image`);
  console.log(`   Original prompt: ${imagePrompt.substring(0, 100)}...`);

  // í”„ë¡¬í”„íŠ¸ í–¥ìƒ (ê³µì‹ ê°€ì´ë“œë¼ì¸ ì ìš©)
  const enhancedPrompt = enhanceImagePrompt(imagePrompt, emotion);
  console.log(`   Enhanced prompt: ${enhancedPrompt.substring(0, 150)}...`);

  // Gemini 2.5 Flash Image ëª¨ë¸ ì‚¬ìš©
  const model = vertexAI.getGenerativeModel({
    model: "gemini-2.5-flash-image",
    // Safety Settings ì¶”ê°€ (Safety Filter ì°¨ë‹¨ ë°©ì§€)
    safetySettings: [
      {
        category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
        threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH,
      },
      {
        category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,
        threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH,
      },
      {
        category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
        threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH,
      },
      {
        category: HarmCategory.HARM_CATEGORY_HARASSMENT,
        threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH,
      },
    ],
  });

  const result = await model.generateContent({
    contents: [
      {
        role: "user",
        parts: [{ text: enhancedPrompt }],
      },
    ],
    generationConfig: {
      temperature: 0.4,
      candidateCount: 1,
    },
  });

  // ì‘ë‹µì„ ì—ëŸ¬ ë°œìƒ ì „ì— ë¡œê¹… (ë””ë²„ê¹…ìš©)
  console.log("ğŸ” ===== Gemini API Response =====");
  console.log(`   Candidates count: ${result.response.candidates?.length || 0}`);
  if (result.response.promptFeedback) {
    console.log("   PromptFeedback:", JSON.stringify(result.response.promptFeedback, null, 2));
  }
  console.log("==================================");

  // ìƒì„¸í•œ ì‘ë‹µ ê²€ì¦
  const response = result.response;

  // 1. candidates ë°°ì—´ í™•ì¸
  if (!response.candidates || response.candidates.length === 0) {
    console.error("âŒ No candidates in Gemini response");
    console.error("   PromptFeedback:", JSON.stringify(response.promptFeedback, null, 2));

    if (response.promptFeedback?.blockReason) {
      throw new Error(`Gemini blocked by safety filter: ${response.promptFeedback.blockReason}`);
    }

    throw new Error("No candidates in Gemini response");
  }

  const candidate = response.candidates[0];

  // 2. finishReason í™•ì¸
  if (candidate.finishReason && candidate.finishReason !== "STOP") {
    console.error("âŒ Generation did not complete normally");
    console.error("   Finish reason:", candidate.finishReason);
    throw new Error(`Gemini generation failed: ${candidate.finishReason}`);
  }

  // 3. ì´ë¯¸ì§€ ë°ì´í„° í™•ì¸ (ì§ì ‘ ì†ì„± ì ‘ê·¼)
  const imageData = candidate.content?.parts?.[0];
  const inlineData = (imageData as unknown as { inlineData?: { data?: string; mimeType?: string } })?.inlineData;

  if (!inlineData || !inlineData.data) {
    console.error("âŒ No image data in candidate");
    console.error("   Candidate structure:", JSON.stringify(candidate, null, 2));
    console.error("   imageData:", JSON.stringify(imageData, null, 2));
    throw new Error("No image data in Gemini response");
  }

  // Base64 ë””ì½”ë”©í•˜ì—¬ Buffer ë°˜í™˜
  const base64Data = inlineData.data;
  const buffer = Buffer.from(base64Data, "base64");

  console.log(`âœ… Background image generated: ${buffer.length} bytes`);
  return buffer;
}

/**
 * Veo 3.1 - ë°°ê²½ ì˜ìƒ ìƒì„± (image-to-video)
 *
 * @param imageUrl - ê¸°ì¤€ ì´ë¯¸ì§€ URL
 * @param prompt - ì˜ìƒ ì„¤ëª…
 * @param emotion - ê°ì •/ë¶„ìœ„ê¸° (ì„ íƒì‚¬í•­, ì¹´ë©”ë¼ ì›€ì§ì„ ìµœì í™”)
 * @returns Operation ì •ë³´
 */
export async function generateVeoVideo(
  imageUrl: string,
  prompt: string,
  emotion?: string
): Promise<{ name: string }> {
  const { GoogleAuth } = await import("google-auth-library");

  // Google Auth í´ë¼ì´ì–¸íŠ¸ ìƒì„±
  const auth = new GoogleAuth({
    scopes: ["https://www.googleapis.com/auth/cloud-platform"],
    ...(credentials && { credentials }),
  });

  const client = await auth.getClient();
  const accessTokenResponse = await client.getAccessToken();

  if (!accessTokenResponse.token) {
    throw new Error("Failed to obtain access token");
  }

  console.log(`ğŸ“¸ Downloading image from: ${imageUrl}`);

  // ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° Base64 ì¸ì½”ë”©
  const imageResponse = await fetch(imageUrl);
  if (!imageResponse.ok) {
    console.error(`âŒ Failed to fetch image: ${imageResponse.status} ${imageResponse.statusText}`);
    console.error(`   Image URL: ${imageUrl}`);
    throw new Error(`Failed to fetch image: ${imageResponse.statusText}`);
  }

  const imageBuffer = await imageResponse.arrayBuffer();
  const imageBase64 = Buffer.from(imageBuffer).toString("base64");
  console.log(`âœ… Image downloaded: ${imageBuffer.byteLength} bytes â†’ ${imageBase64.length} base64 chars`);

  // Veo 3.0 Fast API ì—”ë“œí¬ì¸íŠ¸ (predictLongRunning ì‚¬ìš©)
  const endpoint = `https://${LOCATION}-aiplatform.googleapis.com/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/veo-3.0-fast-generate-001:predictLongRunning`;

  // í”„ë¡¬í”„íŠ¸ í–¥ìƒ (ê³µì‹ ê°€ì´ë“œë¼ì¸ ì ìš©)
  const enhancedPrompt = enhanceVideoPrompt(prompt, emotion);

  console.log(`ğŸ¬ Calling Veo 3.1 API:`);
  console.log(`   Endpoint: ${endpoint}`);
  console.log(`   Original prompt: ${prompt.substring(0, 100)}...`);
  console.log(`   Enhanced prompt: ${enhancedPrompt.substring(0, 150)}...`);

  // API ìš”ì²­ (Veo í˜•ì‹)
  const response = await fetch(endpoint, {
    method: "POST",
    headers: {
      Authorization: `Bearer ${accessTokenResponse.token}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      instances: [
        {
          prompt: enhancedPrompt,
          image: {
            bytesBase64Encoded: imageBase64,
            mimeType: "image/png",
          },
        },
      ],
      parameters: {
        aspectRatio: "16:9",
        resolution: "720p",
        sampleCount: 1,
      },
    }),
  });

  if (!response.ok) {
    const errorText = await response.text();
    console.error("âŒ Veo API request failed:");
    console.error(`   Status: ${response.status} ${response.statusText}`);
    console.error(`   Endpoint: ${endpoint}`);
    console.error(`   Response:`, errorText.substring(0, 1000));
    throw new Error(`Veo API request failed: ${response.status} ${response.statusText}`);
  }

  const result = await response.json();

  // ë””ë²„ê¹…: Veo API ì „ì²´ ì‘ë‹µ í™•ì¸
  console.log(`âœ… Veo video generation API response:`);
  console.log(JSON.stringify(result, null, 2));

  // LRO operation name ì¶”ì¶œ
  const operationName = result.name;
  if (!operationName) {
    console.error("âŒ No operation name in Veo API response");
    console.error("   Full response:", JSON.stringify(result, null, 2));
    throw new Error("No operation name in Veo API response");
  }

  console.log(`âœ… Veo video generation started`);
  console.log(`   Operation name: ${operationName}`);
  console.log(`   Full response:`, JSON.stringify(result, null, 2).substring(0, 500));

  return { name: operationName };
}

/**
 * Veo ë™ì˜ìƒ í”„ë¡¬í”„íŠ¸ í–¥ìƒ
 *
 * Google ê³µì‹ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì˜í™”ì  í‘œí˜„ìœ¼ë¡œ ê°•í™”
 * https://ai.google.dev/gemini-api/docs/video?hl=ko#prompt-guide
 *
 * @param rawPrompt - ì›ë³¸ í”„ë¡¬í”„íŠ¸
 * @param emotion - ê°ì •/ë¶„ìœ„ê¸° (ì¹´ë©”ë¼ ì›€ì§ì„ê³¼ ì¡°ëª… ê²°ì •)
 * @returns í–¥ìƒëœ ë™ì˜ìƒ í”„ë¡¬í”„íŠ¸
 */
function enhanceVideoPrompt(
  rawPrompt: string,
  emotion: string = "professional"
): string {
  // ì´ë¯¸ ìƒì„¸í•œ í”„ë¡¬í”„íŠ¸ì¸ ê²½ìš° (80ì ì´ìƒ, ì¹´ë©”ë¼/ì¡°ëª… ìš©ì–´ í¬í•¨)
  const hasCameraTerms = /shot|camera|tracking|drone|pan|tilt|dolly|zoom|pov|angle/i.test(rawPrompt);
  const hasLightingTerms = /light|lighting|shadow|glow|bright|dark|golden|atmosphere/i.test(rawPrompt);
  const hasMotionTerms = /slow|smooth|gentle|dynamic|subtle|movement|motion|drift/i.test(rawPrompt);

  if (
    rawPrompt.length > 80 &&
    hasCameraTerms &&
    hasLightingTerms &&
    hasMotionTerms
  ) {
    console.log("   âœ“ Video prompt already detailed, using as-is");
    return rawPrompt;
  }

  // ê°ì •ì— ë”°ë¥¸ ì¹´ë©”ë¼ ì›€ì§ì„ ë° ë¶„ìœ„ê¸° ì„¤ì •
  const cinematicStyles = {
    professional: {
      camera: "Steady tracking shot with subtle horizontal pan, maintaining professional composition throughout",
      motion: "Smooth, measured camera movement with gentle transitions",
      lighting: "Balanced ambient lighting with soft natural tones",
      atmosphere: "clean, focused, and authoritative visual narrative",
      pacing: "deliberate and purposeful progression"
    },
    energetic: {
      camera: "Dynamic drone shot with sweeping movement, incorporating quick pans and varied perspectives",
      motion: "Energetic camera work with fluid transitions and active framing",
      lighting: "Vibrant illumination with warm highlights and dynamic contrast",
      atmosphere: "lively, engaging, and momentum-driven visual story",
      pacing: "brisk and exciting progression with rapid visual interest"
    },
    calm: {
      camera: "Slow dolly movement with gentle drift, peaceful and contemplative camera flow",
      motion: "Serene, unhurried camera motion with graceful transitions",
      lighting: "Soft ambient glow with tranquil color temperature",
      atmosphere: "peaceful, meditative, and soothing visual experience",
      pacing: "leisurely and calming progression"
    },
    innovative: {
      camera: "Creative camera angles with experimental movement, modern cinematographic approach",
      motion: "Unconventional camera paths with artistic transitions",
      lighting: "Contemporary lighting design with sleek modern aesthetics",
      atmosphere: "cutting-edge, visually striking, and thought-provoking narrative",
      pacing: "progressive and forward-thinking visual development"
    },
    neutral: {
      camera: "Standard cinematic camera work with natural movement patterns",
      motion: "Balanced camera motion with organic transitions",
      lighting: "Natural lighting conditions with realistic illumination",
      atmosphere: "straightforward, authentic, and clear visual presentation",
      pacing: "steady and natural progression"
    }
  };

  const style = cinematicStyles[emotion.toLowerCase() as keyof typeof cinematicStyles]
    || cinematicStyles.neutral;

  // ê³µì‹ ê°€ì´ë“œë¼ì¸ì— ë”°ë¥¸ ì„œìˆ í˜• í”„ë¡¬í”„íŠ¸ êµ¬ì„±
  const enhancedPrompt = `
${rawPrompt.trim()}.
${style.camera}, creating a ${style.atmosphere}.
${style.motion}, with ${style.lighting} establishing the mood and visual tone.
The sequence unfolds over 8 seconds with ${style.pacing}, featuring smooth temporal continuity and cinematic color grading.
Professional cinematography with film-grade quality, incorporating subtle environmental changes and atmospheric depth throughout the duration.
  `.trim();

  console.log(`   âœ“ Enhanced video prompt from ${rawPrompt.length} to ${enhancedPrompt.length} characters`);
  return enhancedPrompt;
}

/**
 * Veo LRO (Long Running Operation) ìƒíƒœ í™•ì¸
 *
 * @param operationName - Operation name
 * @returns ìƒíƒœ ë° ê²°ê³¼
 */
export async function checkVeoOperation(operationName: string): Promise<{
  done: boolean;
  videoBuffer?: Buffer;
  error?: string;
}> {
  const { GoogleAuth } = await import("google-auth-library");
  const { Storage } = await import("@google-cloud/storage");

  // Google Auth í´ë¼ì´ì–¸íŠ¸ ìƒì„±
  const auth = new GoogleAuth({
    scopes: ["https://www.googleapis.com/auth/cloud-platform"],
    ...(credentials && { credentials }),
  });

  const client = await auth.getClient();
  const accessTokenResponse = await client.getAccessToken();

  if (!accessTokenResponse.token) {
    throw new Error("Failed to obtain access token");
  }

  // operationNameì—ì„œ location ë™ì  ì¶”ì¶œ
  // ì˜ˆ: "projects/.../locations/us-central1/..." â†’ "us-central1"
  const locationMatch = operationName.match(/\/locations\/([^\/]+)\//);
  const operationLocation = locationMatch ? locationMatch[1] : LOCATION;

  // LRO ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸ (ê³µì‹ ë¬¸ì„œ ì¤€ìˆ˜: fetchPredictOperation ì‚¬ìš©)
  // POST ë°©ì‹ìœ¼ë¡œ operationNameì„ bodyì— í¬í•¨í•˜ì—¬ ì „ì†¡
  const endpoint = `https://${operationLocation}-aiplatform.googleapis.com/v1/projects/${PROJECT_ID}/locations/${operationLocation}/publishers/google/models/veo-3.0-fast-generate-001:fetchPredictOperation`;

  console.log(`ğŸ” Veo LRO polling (fetchPredictOperation):`);
  console.log(`   Operation location: ${operationLocation}`);
  console.log(`   Operation name: ${operationName}`);
  console.log(`   Endpoint: ${endpoint}`);

  const response = await fetch(endpoint, {
    method: "POST",
    headers: {
      Authorization: `Bearer ${accessTokenResponse.token}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      operationName,
    }),
  });

  if (!response.ok) {
    const errorText = await response.text();
    console.error("âŒ Veo LRO polling failed:");
    console.error(`   Status: ${response.status} ${response.statusText}`);
    console.error(`   Operation: ${operationName}`);
    console.error(`   Extracted location: ${operationLocation}`);
    console.error(`   Default location (env): ${LOCATION}`);
    console.error(`   Endpoint: ${endpoint}`);
    console.error(`   Response:`, errorText.substring(0, 500));

    // 404 ì—ëŸ¬ëŠ” eventual consistency - ì¬ì‹œë„ ê³„ì†
    if (response.status === 404) {
      console.log("â³ 404 - Operation not yet available (eventual consistency)");
      console.log(`   Operation will be retried by polling function`);
      console.log(`   Location: ${operationLocation}`);
      return {
        done: false,  // â† FIXED: ì¬ì‹œë„ ê³„ì†
      };
    }

    // ë‹¤ë¥¸ HTTP ì—ëŸ¬ (ê¶Œí•œ, í• ë‹¹ëŸ‰ ë“±)ëŠ” ì‹¤íŒ¨ë¡œ ì²˜ë¦¬
    console.error("ğŸš¨ Non-404 error - marking as failed");
    return {
      done: true,
      error: `LRO polling failed: ${response.status} ${response.statusText}`,
    };
  }

  const operation = await response.json();

  // ì‘ì—…ì´ ì•„ì§ ì§„í–‰ ì¤‘ì¸ ê²½ìš°
  if (!operation.done) {
    console.log(`â³ Veo operation in progress: ${operationName}`);
    return {
      done: false,
    };
  }

  // ì—ëŸ¬ê°€ ë°œìƒí•œ ê²½ìš°
  if (operation.error) {
    console.error("Veo operation failed:", operation.error);
    return {
      done: true,
      error: operation.error.message || "Veo operation failed",
    };
  }

  // ì„±ê³µí•œ ê²½ìš° - ë¹„ë””ì˜¤ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
  try {
    // ğŸ” ì „ì²´ operation response ë¡œê¹… (ë””ë²„ê¹…ìš©)
    console.log(`ğŸ“‹ Full operation response:`, JSON.stringify(operation, null, 2));

    // Veo API ì‘ë‹µ í˜•ì‹: operation.response.videos[]
    const videos = operation.response?.videos;
    if (!videos || videos.length === 0) {
      console.error(`âŒ No videos in operation response!`);
      console.error(`   Operation name: ${operationName}`);
      console.error(`   Response structure:`, JSON.stringify(operation.response, null, 2));
      throw new Error("No generated videos in operation response");
    }

    const videoFile = videos[0];
    let videoBuffer: Buffer;

    // Case 1: GCS URIë¡œ ë°˜í™˜ëœ ê²½ìš° (outputGcsUri ì§€ì • ì‹œ)
    if (videoFile.gcsUri) {
      const gcsUri = videoFile.gcsUri;
      console.log(`ğŸ“¹ Downloading Veo video from GCS: ${gcsUri}`);

      // GCS URI íŒŒì‹±: gs://bucket-name/path/to/file.mp4
      const match = gcsUri.match(/^gs:\/\/([^\/]+)\/(.+)$/);
      if (!match) {
        console.error(`âŒ Invalid GCS URI format: ${gcsUri}`);
        throw new Error(`Invalid GCS URI format: ${gcsUri}`);
      }

      const [, bucketName, filePath] = match;

      console.log(`ğŸ“¦ GCS download details:`);
      console.log(`   Bucket: ${bucketName}`);
      console.log(`   File path: ${filePath}`);

      // Cloud Storage í´ë¼ì´ì–¸íŠ¸ë¡œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
      const storage = new Storage({
        ...(credentials && { credentials }),
      });

      const bucket = storage.bucket(bucketName);
      const file = bucket.file(filePath);

      const [downloadedBuffer] = await file.download();
      videoBuffer = downloadedBuffer;

      console.log(`âœ… Veo video downloaded from GCS: ${videoBuffer.length} bytes`);
    }
    // Case 2: Base64ë¡œ ë°˜í™˜ëœ ê²½ìš° (outputGcsUri ë¯¸ì§€ì • ì‹œ - ê¸°ë³¸ê°’)
    else if (videoFile.bytesBase64Encoded) {
      console.log(`ğŸ“¹ Veo video returned as Base64 (no GCS bucket specified)`);
      videoBuffer = Buffer.from(videoFile.bytesBase64Encoded, "base64");
      console.log(`âœ… Veo video decoded from Base64: ${videoBuffer.length} bytes`);
    }
    // Case 3: ë‘˜ ë‹¤ ì—†ëŠ” ê²½ìš° - ì—ëŸ¬
    else {
      console.error(`âŒ No video data in response!`);
      console.error(`   Video file structure:`, JSON.stringify(videoFile, null, 2));
      throw new Error("No gcsUri or bytesBase64Encoded in operation response");
    }

    return {
      done: true,
      videoBuffer,
    };
  } catch (error) {
    console.error("âŒ Failed to download Veo video:");
    console.error(`   Operation: ${operationName}`);
    console.error(`   Error type: ${error instanceof Error ? error.constructor.name : typeof error}`);
    console.error(`   Error message: ${error instanceof Error ? error.message : String(error)}`);

    if (error instanceof Error && error.stack) {
      console.error(`   Stack trace:`, error.stack);
    }

    return {
      done: true,
      error: error instanceof Error ? error.message : "Failed to download video",
    };
  }
}
